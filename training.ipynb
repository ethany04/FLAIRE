{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Loading the Data"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:39.450247Z","iopub.status.busy":"2023-05-08T06:46:39.449766Z","iopub.status.idle":"2023-05-08T06:46:39.457761Z","shell.execute_reply":"2023-05-08T06:46:39.45628Z","shell.execute_reply.started":"2023-05-08T06:46:39.450207Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","\n","transform = transforms.Compose([transforms.Resize((64, 64)),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n","                               ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:40.213855Z","iopub.status.busy":"2023-05-08T06:46:40.213439Z","iopub.status.idle":"2023-05-08T06:46:40.230643Z","shell.execute_reply":"2023-05-08T06:46:40.228995Z","shell.execute_reply.started":"2023-05-08T06:46:40.213823Z"},"trusted":true},"outputs":[],"source":["training_dataset = datasets.ImageFolder(root='data/train', transform=transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:40.922499Z","iopub.status.busy":"2023-05-08T06:46:40.921822Z","iopub.status.idle":"2023-05-08T06:46:40.929843Z","shell.execute_reply":"2023-05-08T06:46:40.928338Z","shell.execute_reply.started":"2023-05-08T06:46:40.922458Z"},"trusted":true},"outputs":[],"source":["training_dataset.classes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:41.571215Z","iopub.status.busy":"2023-05-08T06:46:41.570853Z","iopub.status.idle":"2023-05-08T06:46:41.582656Z","shell.execute_reply":"2023-05-08T06:46:41.581765Z","shell.execute_reply.started":"2023-05-08T06:46:41.571187Z"},"trusted":true},"outputs":[],"source":["validation_dataset = datasets.ImageFolder(root='data/val', transform=transform)\n","test_dataset = datasets.ImageFolder(root='data/test', transform=transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:42.223875Z","iopub.status.busy":"2023-05-08T06:46:42.222872Z","iopub.status.idle":"2023-05-08T06:46:42.230013Z","shell.execute_reply":"2023-05-08T06:46:42.228647Z","shell.execute_reply.started":"2023-05-08T06:46:42.223833Z"},"trusted":true},"outputs":[],"source":["batch_size = 64\n","train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:42.87232Z","iopub.status.busy":"2023-05-08T06:46:42.871887Z","iopub.status.idle":"2023-05-08T06:46:43.84282Z","shell.execute_reply":"2023-05-08T06:46:43.841549Z","shell.execute_reply.started":"2023-05-08T06:46:42.872256Z"},"trusted":true},"outputs":[],"source":["batch = next(iter(train_loader))\n","images,labels = batch\n","print(images.shape, labels.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Visualizing Images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:46.127215Z","iopub.status.busy":"2023-05-08T06:46:46.12642Z","iopub.status.idle":"2023-05-08T06:46:46.768982Z","shell.execute_reply":"2023-05-08T06:46:46.768018Z","shell.execute_reply.started":"2023-05-08T06:46:46.127176Z"},"trusted":true},"outputs":[],"source":["for i in range(6):\n","    plt.subplot(2, 3, i + 1)\n","    plt.imshow(images[i][0])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:50.464958Z","iopub.status.busy":"2023-05-08T06:46:50.464379Z","iopub.status.idle":"2023-05-08T06:46:50.472382Z","shell.execute_reply":"2023-05-08T06:46:50.471183Z","shell.execute_reply.started":"2023-05-08T06:46:50.464924Z"},"trusted":true},"outputs":[],"source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),  \n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),  # output: 32 x 16 x 16\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),  # output: 64 x 8 x 8\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),  # output: 128 x 4 x 4\n","            nn.Flatten(),\n","            nn.Linear(128*4*4, 1024),  # Updated linear layer input size\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 2)\n","        )\n","\n","    def forward(self, X):\n","        return self.network(X)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T06:46:53.527762Z","iopub.status.busy":"2023-05-08T06:46:53.527373Z","iopub.status.idle":"2023-05-08T06:49:50.515934Z","shell.execute_reply":"2023-05-08T06:49:50.514759Z","shell.execute_reply.started":"2023-05-08T06:46:53.527733Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0], Model Accuracy: 0.6406\n","Epoch [1], Model Accuracy: 0.6392\n","Epoch [2], Model Accuracy: 0.5731\n","Epoch [3], Model Accuracy: 0.6025\n","Epoch [4], Model Accuracy: 0.7583\n","Epoch [5], Model Accuracy: 0.8249\n","Epoch [6], Model Accuracy: 0.8318\n","Epoch [7], Model Accuracy: 0.8346\n","Epoch [8], Model Accuracy: 0.8952\n","Epoch [9], Model Accuracy: 0.8571\n","Epoch [10], Model Accuracy: 0.8943\n","Epoch [11], Model Accuracy: 0.8934\n","Epoch [12], Model Accuracy: 0.8814\n","Epoch [13], Model Accuracy: 0.9040\n","Epoch [14], Model Accuracy: 0.9177\n","Epoch [15], Model Accuracy: 0.9099\n","Epoch [16], Model Accuracy: 0.8961\n","Epoch [17], Model Accuracy: 0.8874\n","Epoch [18], Model Accuracy: 0.8511\n","Epoch [19], Model Accuracy: 0.8952\n"]}],"source":["model = CNNModel()\n","loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n","num_epochs = 20\n","\n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","for epoch in range(num_epochs):\n","    for batch in train_loader:\n","        #forward pass\n","        inputs, labels = batch\n","        outputs = model(inputs)\n","        l = loss(outputs, labels)\n","        #backward pass\n","        l.backward()\n","        #weight update\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    \n","    batch_acc = []\n","    for batch in val_loader:\n","        inputs, labels = batch\n","        outputs = model(inputs)\n","        acc = accuracy(outputs, labels)\n","        batch_acc.append(acc)\n","    epoch_acc = torch.stack(batch_acc).mean()\n","    print(f\"Epoch [{epoch}], Model Accuracy: {epoch_acc.item():.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy of Model is 0.9470\n","Processed 100 images in 1.185 seconds, 84.38 FPS\n"]}],"source":["import time\n","\n","# Define the device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Send the model to the defined device\n","model.to(device)\n","\n","# Initialize a list to store accuracies for each batch\n","batch_acc = []\n","\n","# Start timing\n","start_time = time.time()\n","\n","# Loop over all batches in the test loader\n","for inputs, labels in test_loader:\n","    # Send data to the device\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    \n","    # No need to track gradients for inference\n","    with torch.no_grad():\n","        outputs = model(inputs)\n","    \n","    # Calculate accuracy and store it\n","    acc = accuracy(outputs, labels)\n","    batch_acc.append(acc)\n","\n","# End timing\n","end_time = time.time()\n","\n","# Calculate the mean accuracy across all batches\n","test_accuracy = torch.stack(batch_acc).mean()\n","print(f\"Test accuracy of Model is {test_accuracy:.4f}\")\n","\n","# Calculate the elapsed time for processing\n","elapsed_time = end_time - start_time\n","\n","# Calculate the total number of images processed\n","total_images = len(test_loader.dataset)\n","\n","# Calculate frames per second (FPS)\n","fps = total_images / elapsed_time\n","print(f\"Processed {total_images} images in {elapsed_time:.3f} seconds, {fps:.2f} FPS\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_accuracy_float = float(f\"{test_accuracy:.4f}\")\n","if test_accuracy_float > 0.9427:\n","    torch.save(model, 'model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model on the test images: 92.0%\n","Frame 0: True Label - 0, Predicted Label - 0\n","Frame 1: True Label - 0, Predicted Label - 0\n","Frame 2: True Label - 0, Predicted Label - 0\n","Frame 3: True Label - 0, Predicted Label - 0\n","Frame 4: True Label - 0, Predicted Label - 0\n","Frame 5: True Label - 0, Predicted Label - 0\n","Frame 6: True Label - 0, Predicted Label - 0\n","Frame 7: True Label - 0, Predicted Label - 0\n","Frame 8: True Label - 0, Predicted Label - 0\n","Frame 9: True Label - 0, Predicted Label - 0\n","Frame 10: True Label - 0, Predicted Label - 0\n","Frame 11: True Label - 0, Predicted Label - 0\n","Frame 12: True Label - 0, Predicted Label - 0\n","Frame 13: True Label - 0, Predicted Label - 0\n","Frame 14: True Label - 0, Predicted Label - 0\n","Frame 15: True Label - 0, Predicted Label - 0\n","Frame 16: True Label - 0, Predicted Label - 0\n","Frame 17: True Label - 0, Predicted Label - 0\n","Frame 18: True Label - 0, Predicted Label - 0\n","Frame 19: True Label - 0, Predicted Label - 0\n","Frame 20: True Label - 0, Predicted Label - 0\n","Frame 21: True Label - 0, Predicted Label - 0\n","Frame 22: True Label - 0, Predicted Label - 0\n","Frame 23: True Label - 0, Predicted Label - 1\n","Frame 24: True Label - 0, Predicted Label - 0\n","Frame 25: True Label - 0, Predicted Label - 0\n","Frame 26: True Label - 0, Predicted Label - 0\n","Frame 27: True Label - 0, Predicted Label - 0\n","Frame 28: True Label - 0, Predicted Label - 0\n","Frame 29: True Label - 0, Predicted Label - 0\n","Frame 30: True Label - 0, Predicted Label - 0\n","Frame 31: True Label - 0, Predicted Label - 0\n","Frame 32: True Label - 0, Predicted Label - 1\n","Frame 33: True Label - 0, Predicted Label - 0\n","Frame 34: True Label - 0, Predicted Label - 0\n","Frame 35: True Label - 0, Predicted Label - 0\n","Frame 36: True Label - 0, Predicted Label - 0\n","Frame 37: True Label - 0, Predicted Label - 1\n","Frame 38: True Label - 0, Predicted Label - 1\n","Frame 39: True Label - 0, Predicted Label - 0\n","Frame 40: True Label - 0, Predicted Label - 0\n","Frame 41: True Label - 0, Predicted Label - 1\n","Frame 42: True Label - 0, Predicted Label - 1\n","Frame 43: True Label - 0, Predicted Label - 0\n","Frame 44: True Label - 0, Predicted Label - 0\n","Frame 45: True Label - 0, Predicted Label - 1\n","Frame 46: True Label - 0, Predicted Label - 0\n","Frame 47: True Label - 1, Predicted Label - 1\n","Frame 48: True Label - 1, Predicted Label - 1\n","Frame 49: True Label - 1, Predicted Label - 1\n","Frame 50: True Label - 1, Predicted Label - 1\n","Frame 51: True Label - 1, Predicted Label - 1\n","Frame 52: True Label - 1, Predicted Label - 1\n","Frame 53: True Label - 1, Predicted Label - 1\n","Frame 54: True Label - 1, Predicted Label - 1\n","Frame 55: True Label - 1, Predicted Label - 1\n","Frame 56: True Label - 1, Predicted Label - 1\n","Frame 57: True Label - 1, Predicted Label - 1\n","Frame 58: True Label - 1, Predicted Label - 1\n","Frame 59: True Label - 1, Predicted Label - 1\n","Frame 60: True Label - 1, Predicted Label - 1\n","Frame 61: True Label - 1, Predicted Label - 1\n","Frame 62: True Label - 1, Predicted Label - 1\n","Frame 63: True Label - 1, Predicted Label - 1\n","Frame 64: True Label - 1, Predicted Label - 1\n","Frame 65: True Label - 1, Predicted Label - 1\n","Frame 66: True Label - 1, Predicted Label - 1\n","Frame 67: True Label - 1, Predicted Label - 1\n","Frame 68: True Label - 1, Predicted Label - 1\n","Frame 69: True Label - 1, Predicted Label - 1\n","Frame 70: True Label - 1, Predicted Label - 1\n","Frame 71: True Label - 1, Predicted Label - 1\n","Frame 72: True Label - 1, Predicted Label - 1\n","Frame 73: True Label - 1, Predicted Label - 1\n","Frame 74: True Label - 1, Predicted Label - 1\n","Frame 75: True Label - 1, Predicted Label - 1\n","Frame 76: True Label - 1, Predicted Label - 1\n","Frame 77: True Label - 1, Predicted Label - 1\n","Frame 78: True Label - 1, Predicted Label - 1\n","Frame 79: True Label - 1, Predicted Label - 1\n","Frame 80: True Label - 1, Predicted Label - 1\n","Frame 81: True Label - 1, Predicted Label - 1\n","Frame 82: True Label - 1, Predicted Label - 1\n","Frame 83: True Label - 1, Predicted Label - 1\n","Frame 84: True Label - 1, Predicted Label - 1\n","Frame 85: True Label - 1, Predicted Label - 1\n","Frame 86: True Label - 1, Predicted Label - 1\n","Frame 87: True Label - 1, Predicted Label - 1\n","Frame 88: True Label - 1, Predicted Label - 1\n","Frame 89: True Label - 1, Predicted Label - 0\n","Frame 90: True Label - 1, Predicted Label - 1\n","Frame 91: True Label - 1, Predicted Label - 1\n","Frame 92: True Label - 1, Predicted Label - 1\n","Frame 93: True Label - 1, Predicted Label - 1\n","Frame 94: True Label - 1, Predicted Label - 1\n","Frame 95: True Label - 1, Predicted Label - 1\n","Frame 96: True Label - 1, Predicted Label - 1\n","Frame 97: True Label - 1, Predicted Label - 1\n","Frame 98: True Label - 1, Predicted Label - 1\n","Frame 99: True Label - 1, Predicted Label - 1\n"]}],"source":["saved_model = torch.load('0.95.pth')\n","saved_model.eval()\n","\n","correct = 0\n","total = 0\n","with torch.no_grad():  # Disable gradient tracking\n","    for inputs, labels in test_loader:\n","        outputs = saved_model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)  # Get the predicted classes\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f'Accuracy of the model on the test images: {accuracy}%')\n","\n","import torch\n","\n","# Loop through the test dataset\n","for i, (inputs, labels) in enumerate(test_loader):\n","    outputs = saved_model(inputs)\n","    _, predicted = torch.max(outputs, 1)\n","\n","    for j in range(inputs.size(0)):  # Iterate over each image in the batch\n","        image = inputs[j]  # Get the image\n","        true_label = labels[j].item()  # Actual label\n","        pred_label = predicted[j].item()  # Predicted label\n","\n","        print(f\"Frame {i * test_loader.batch_size + j}: True Label - {true_label}, Predicted Label - {pred_label}\")\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":4}
